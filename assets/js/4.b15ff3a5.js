(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{254:function(t,e,s){t.exports=s.p+"assets/img/hueui.d9924730.png"},255:function(t,e,s){t.exports=s.p+"assets/img/hueui-1.a65cdf80.png"},256:function(t,e,s){t.exports=s.p+"assets/img/hueui-2.92bd54ca.png"},257:function(t,e,s){t.exports=s.p+"assets/img/hueui-3.a07f335d.png"},258:function(t,e,s){t.exports=s.p+"assets/img/hueui-4.6393aa11.png"},259:function(t,e,s){t.exports=s.p+"assets/img/hueui-5.dfd2d6bb.png"},260:function(t,e,s){t.exports=s.p+"assets/img/hueui-6.bac89622.png"},261:function(t,e,s){t.exports=s.p+"assets/img/hueui-7.7acdfccb.png"},262:function(t,e,s){t.exports=s.p+"assets/img/hueui-8.87999fc7.png"},263:function(t,e,s){t.exports=s.p+"assets/img/hueui-9.d6be81e9.png"},264:function(t,e,s){t.exports=s.p+"assets/img/hueui-10.a5bd7988.png"},273:function(t,e,s){"use strict";s.r(e);var a=s(0),i=Object(a.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"lab-4-twitter-tweets-sentiment-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lab-4-twitter-tweets-sentiment-analysis"}},[t._v("#")]),t._v(" Lab 4: Twitter tweets sentiment analysis")]),t._v(" "),a("p",[a("strong",[t._v("Objective:")])]),t._v(" "),a("p",[t._v("To use Hive, HUE, HDFS and YARN to compute the sentiment of twitter tweets using SQL commands.")]),t._v(" "),a("p",[a("strong",[t._v("Successful Outcome:")])]),t._v(" "),a("ol",[a("li",[t._v("Configuring Hive to add new jars.")]),t._v(" "),a("li",[t._v("Use Hive SQL lines to manipulate files and show meaningful outputs.")]),t._v(" "),a("li",[t._v("Utilize HUE real-time editors.")])]),t._v(" "),a("p",[t._v("In this exercise, we will load twitter tweets about the blockbuster movie of 2019 The Avengers Endgame. We will analyze the sentiment of the tweets against AFINN dictionary.")]),t._v(" "),a("h2",{attrs:{id:"access-hue-ui"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#access-hue-ui"}},[t._v("#")]),t._v(" Access HUE UI")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("Using the browser, access HUE UI. (http://quickstart.cloudera:8888)")])]),t._v(" "),a("li",[a("p",[t._v("Credientials for the log-in screen is cloudera and password is cloudera:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(254),alt:"HUE1"}})])]),t._v(" "),a("li",[a("p",[t._v("When you get the pop-up to check Hue 4, just click on the X sign:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(255),alt:"HUE2"}})])]),t._v(" "),a("li",[a("p",[t._v("There are multiple options to use for HUE UI, we will start using them in the next section:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(256),alt:"HUE3"}})])])]),t._v(" "),a("h2",{attrs:{id:"importing-the-dataset"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#importing-the-dataset"}},[t._v("#")]),t._v(" Importing the dataset")]),t._v(" "),a("p",[t._v("We will import the datasets needed for this exercise which are the tweets and the sentiments dictionary. We will use both the UI and the Hive Editor to import.")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("We will import first the dictionary from the Hive Editor, access it through the UI as you can see in the last step in the earlier exercise.")]),t._v(" "),a("p",[a("img",{attrs:{src:s(257),alt:"HUE4"}})])]),t._v(" "),a("li",[a("p",[t._v("The dataset is available in the labs HDFS location under (/user/cloudera/twitter_sentiment/dictionary.tsv). We will import it using the following SQL lines:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("CREATE EXTERNAL TABLE dictionary (\n    type string,\n    length int,\n    word string,\n    pos string,\n    stemmed string,\n    polarity string\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t'\nSTORED AS TEXTFILE\nLOCATION '/user/cloudera/twitter_sentiment/dictionary';\n")])])])]),t._v(" "),a("li",[a("p",[t._v("After copying the the lines to the editor, run them using the play button:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(258),alt:"HUE5"}})])]),t._v(" "),a("li",[a("p",[t._v("Now, let's add the tweets but through HUE UI, let's start by adding a table. Start by clicking on the + sign:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(259),alt:"HUE6"}})])]),t._v(" "),a("li",[a("p",[t._v("Now, to add the file to the import wizard click on the end of Path field which is the .. button:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(260),alt:"HUE7"}})])]),t._v(" "),a("li",[a("p",[t._v("Choose the file tweets.txt from the location "),a("code",[t._v("/user/cloudera/twitter_sentiment/")])]),t._v(" "),a("p",[a("img",{attrs:{src:s(261),alt:"HUE8"}})])]),t._v(" "),a("li",[a("p",[t._v("After it's uploaded you'll see the UI expand with options and a preview of the data, click next:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(262),alt:"HUE9"}})])]),t._v(" "),a("li",[a("p",[t._v("Check the options in the submission page, but in our case we don't need to change anything, so go ahead and click Submit:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(263),alt:"HUE10"}})])]),t._v(" "),a("li",[a("p",[t._v("Now you should be able to see both tables in the UI:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(264),alt:"HUE11"}})])]),t._v(" "),a("li",[a("p",[t._v("Let's go back to the Hive editor again and start the next section.")])])]),t._v(" "),a("h2",{attrs:{id:"process-and-compute-the-sentiment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#process-and-compute-the-sentiment"}},[t._v("#")]),t._v(" Process and compute the sentiment")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("Let's start with creating few views, starting with first of all to divide tweet text to an array of words:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("create view arraize_it as select id, words from tweets lateral view explode(sentences(lower(text))) dummy as words;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Now, let's explode each array into lines:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("create view explode_it as select id, word from arraize_it lateral view explode(words) dummy as word;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Now let's utilize the join function to pair words with their scores and compute the sentiment:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("create view compute_it as select\n    id,\n    explode_it.word,\n    case d.polarity\n      when  'negative' then -1\n      when 'positive' then 1\n      else 0 end as polarity\n from explode_it left outer join dictionary d on explode_it.word = d.word;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Now let's label them with being positive, negative or neutral in a new table:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("create table tweets_sentiment stored as orc as select\n id,\n case\n   when sum( polarity ) > 0 then 'positive'\n   when sum( polarity ) < 0 then 'negative'\n   else 'neutral' end as sentiment\nfrom compute_it group by id;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("In the end, let's put everything together and attach the results to the original tweets:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("CREATE TABLE tweets_final\nSTORED AS ORC\nAS\nSELECT\n  t.*,\n  case s.sentiment\n    when 'positive' then 2\n    when 'neutral' then 1\n    when 'negative' then 0\n  end as sentiment\nFROM tweets t LEFT OUTER JOIN tweets_sentiment s on t.id = s.id;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Let's do a simple select to see the results:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select * from tweets_final limit 30;\n")])])])])]),t._v(" "),a("h2",{attrs:{id:"let-s-do-some-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#let-s-do-some-analysis"}},[t._v("#")]),t._v(" Let's do some analysis")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("Find out the top 25 retweeted tweets and whether they are neutral, positive or negative.")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT distinct text, retweetcount, sentiment from tweets_final\norder by retweetcount desc\nlimit 25;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Using the view explode_it, let's analyze what are the top 25 words used in the tweets in the dataset.")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select count(word) as cnt, word from explode_it\ngroup by word\norder by cnt desc;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Using tweets_final table, let's try to find how many tweets are positive, negative or neutral and chart them using a pie chart.")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select count(sentiment) as cnt, sentiment from tweets_final\ngroup by sentiment\norder by cnt desc;\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Do this yourself, bring back the average number of retweets in this dataset.")])])])])}),[],!1,null,null,null);e.default=i.exports}}]);